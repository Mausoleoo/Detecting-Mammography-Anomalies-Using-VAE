# Description
A Variational Autoencoder (VAE) was implemented from scratch to generate breast mammography images. The model was trained on 1,000 healthy breast images, specifically focusing on mediolateral oblique (MLO) views of the right breast. The architecture employs convolutional layers in the encoder and deconvolutional layers in the decoder to process and reconstruct images. The training utilized the Evidence Lower Bound (ELBO) as the loss function, with a latent space of dimension 1024 to encode the key features of the input data. This approach effectively captures the underlying patterns in the dataset, enabling the **generation of realistic mammography images**.

---------------------------------------------------------------------------------------------------------------------------------------------
# Objective

To develop a model for generating synthetic mammography images that can be used for data augmentation, addressing the challenge of limited data availability. By leveraging the relevant information learned from real data, the generated images provide valuable additional samples for training, improving model performance and robustness in medical imaging tasks.

---------------------------------------------------------------------------------------------------------------------------------------------

# Libraries

Torch 2.4.1

Pandas 2.1.3

Numpy 1.26.2

Matplotlib 3.8.3


---------------------------------------------------------------------------------------------------------------------------------------------
# Dataset

The VinDr-Mammo dataset was used, containing images from 5,000 patients, with 4 images per patient, totaling 20,000 images. Each patient has 2 views for both breasts. The dataset's accompanying CSV file, Metadata.csv, was slightly modified to suit the specific needs of the project.

The dataset was previously preprocessed by SSMan and downloaded from

https://www.kaggle.com/datasets/ssmann/vindr-mammo-dataset

---------------------------------------------------------------------------------------------------------------------------------------------
# Architecture

The Variational Autoencoder (VAE) consists of an encoder, a latent space, and a decoder

### Encoder 

The encoder compresses 128√ó128x1 images into a lower-dimensional latent representation. It uses four convolutional layers with ReLU activations, progressively increasing the number of filters (32, 64, 128, 256) while reducing spatial dimensions via max-pooling, resulting in a flattened vector. Two fully connected layers produce the mean and log-variance for the latent space.

### Latent Space

The latent vector ùëß is sampled from the learned Normal distribution using the reparameterization trick.

### Decoder

The decoder reconstructs images from ùëß using four transposed convolutional layers with ReLU activations, progressively decreasing the number of filters (256, 128, 64, 32) while upsampling spatial dimensions. The final layer applies a sigmoid activation to output a 128√ó128√ó1 normalized image.



---------------------------------------------------------------------------------------------------------------------------------------------
# Training 

Due to computational limitations, a sample of 1,000 images was used for training, consisting exclusively of images with no findings (healthy) and MLO views of the right breast. The model was trained for 60 epochs, with all images resized to 128x128 to ensure consistency and optimize processing efficiency.

The model showed a consistent decrease in loss throughout training, and it appeared that the loss would continue to improve with further training. However, I was unable to continue due to time constraints and the cost associated with using Google Colab Pro for extended training sessions.

![image](https://github.com/user-attachments/assets/a4b67526-2fc2-4ca3-897f-b14007532798)


---------------------------------------------------------------------------------------------------------------------------------------------
# Generated Images


The images are entirely generated by the Variational Autoencoder (VAE). The process begins by encoding features from real images into the latent space. In the latent space, additional noise is introduced, sampled from a normal distribution N(0,1). This noise ensures variability and allows the VAE to generate diverse outputs. The noisy latent vector is then passed through the decoder, which reconstructs the features into new images. This process makes the generated images unique and distinct from the original inputs, demonstrating the generative capability of the VAE.

![image](https://github.com/user-attachments/assets/89f13228-8364-4ef6-8c1b-471eaaf0d0a5)


---------------------------------------------------------------------------------------------------------------------------------------------

# Conclusion


In conclusion, while the generated images are not of high resolution, the model demonstrates the potential to achieve higher quality outputs with additional layers, larger input image sizes, and extended training. However, such improvements come at the cost of requiring significantly more computational resources, which would be essential for handling the increased complexity and data processing demands.
