# Description
A Variational Autoencoder (VAE) was implemented from scratch to generate breast mammography images. The model was trained on 1,000 healthy breast images, specifically focusing on mediolateral oblique (MLO) views of the right breast. The architecture employs convolutional layers in the encoder and deconvolutional layers in the decoder to process and reconstruct images. The training utilized the Evidence Lower Bound (ELBO) as the loss function, with a latent space of dimension 1024 to encode the key features of the input data. This approach effectively captures the underlying patterns in the dataset, enabling the **generation of realistic mammography images**.

---------------------------------------------------------------------------------------------------------------------------------------------
# Libraries

Torch 2.4.1

Pandas 2.1.3

Numpy 1.26.2

Matplotlib 3.8.3


---------------------------------------------------------------------------------------------------------------------------------------------
# Dataset

The VinDr-Mammo dataset was used, containing images from 5,000 patients, with 4 images per patient, totaling 20,000 images. Each patient has 2 views for both breasts. The dataset's accompanying CSV file, Metadata.csv, was slightly modified to suit the specific needs of the project.

The dataset was previously preprocessed by SSMan and downloaded from

https://www.kaggle.com/datasets/ssmann/vindr-mammo-dataset

---------------------------------------------------------------------------------------------------------------------------------------------
# Architecture

The Variational Autoencoder (VAE) consists of an encoder, a latent space, and a decoder

### Encoder 

The encoder compresses 128√ó128x1 images into a lower-dimensional latent representation. It uses four convolutional layers with ReLU activations, progressively increasing the number of filters (32, 64, 128, 256) while reducing spatial dimensions via max-pooling, resulting in a flattened vector. Two fully connected layers produce the mean and log-variance for the latent space.

### Latent Space

The latent vector ùëß is sampled from the learned Normal distribution using the reparameterization trick.

### Decoder

The decoder reconstructs images from ùëß using four transposed convolutional layers with ReLU activations, progressively decreasing the number of filters (256, 128, 64, 32) while upsampling spatial dimensions. The final layer applies a sigmoid activation to output a 128√ó128√ó1 normalized image.



---------------------------------------------------------------------------------------------------------------------------------------------
# Training 

Due to computational limitations, a sample of 1,000 images was used for training, consisting exclusively of images with no findings (healthy) and MLO views of the right breast. The model was trained for 60 epochs, with all images resized to 128x128 to ensure consistency and optimize processing efficiency.

The model showed a consistent decrease in loss throughout training, and it appeared that the loss would continue to improve with further training. However, I was unable to continue due to time constraints and the cost associated with using Google Colab Pro for extended training sessions.

![image](https://github.com/user-attachments/assets/a4b67526-2fc2-4ca3-897f-b14007532798)


---------------------------------------------------------------------------------------------------------------------------------------------
# Generated Images


The images are entirely generated by the Variational Autoencoder (VAE). The process begins by encoding features from real images into the latent space. In the latent space, additional noise is introduced, sampled from a normal distribution N(0,1). This noise ensures variability and allows the VAE to generate diverse outputs. The noisy latent vector is then passed through the decoder, which reconstructs the features into new images. This process makes the generated images unique and distinct from the original inputs, demonstrating the generative capability of the VAE.

![image](https://github.com/user-attachments/assets/89f13228-8364-4ef6-8c1b-471eaaf0d0a5)


---------------------------------------------------------------------------------------------------------------------------------------------
# Test

The main goal of this project is to detect anomalies in breast mammographies by analyzing the reconstruction error in the loss function. The model has been trained exclusively on healthy images, meaning that when it encounters a breast with an anomaly, the reconstruction error is likely to be higher, as the model struggles to accurately recreate features it has not learned to recognize.

To analyze the model's performance, 20 healthy images from the test set of the VinDr-Mammo dataset were randomly selected and passed through the model to examine the reconstruction error. The same process was applied to 20 images with anomalies, allowing for a comparison of how the model handles both healthy and anomalous mammographies.

The results from the healthy images are as follows

![image](https://github.com/user-attachments/assets/e9218e20-09da-4fbc-9930-573cb48222c8)

The results from the images with findings are as follows

![image](https://github.com/user-attachments/assets/4a3e98fb-3ebd-4326-b6b3-08159edb6b73)

---------------------------------------------------------------------------------------------------------------------------------------------
# Conclusion

Despite the model not achieving a low loss and the generated images lacking high quality, it has still learned some useful features. This is evident from the fact that the loss for healthy images is considerably lower compared to the loss for images with findings. 

Probably with more training images (only 1,000 were used for this project) and more **epochs**, it is likely that the model could produce higher-definition images and further reduce the reconstruction loss.
